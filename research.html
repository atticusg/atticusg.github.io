<!DOCTYPE html>
<html>
  <head>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <link  href="assets/latex.css" rel="stylesheet">
    <meta charset="utf-8">
    <title>AG</title>
  </head>

  <body>
    <header class= "header"><h1>Research Highlights <br/> (See <a href="https://scholar.google.com/citations?user=w2Qzno8AAAAJ&hl=en">Google Scholar</a> a full list of papers)</h1></header>
    <div class="sidenav">
      <h4><a href="index.html">Home</a></h4>
      <h4><a href="assets/AtticusCV.pdf">CV</a></h4>
      <h4><a href="research.html">Research</a></h4>
    </div>

    <div class="container math">

      <div style="height: 100px">
        <p style="margin: 0px 0px 0px 0px">
          <b><i>Causal abstraction for faithful model interpretation</i></b><br/>
          <b>Atticus Geiger</b>, Christopher Potts, Thomas Icard<br/>
          <i>Preprint </i><br/>
          <a href="https://arxiv.org/abs/2301.04709">pdf</a>
          <a href="assets/JMLR.tex">bibtex</a>
        </p>
      </div>

      <div style="height: 100px">
        <p style="margin: 0px 0px 0px 0px">
          <b><i>Finding alignments between interpretable causal variables and distributed neural representations</i></b><br/>
          <b>Atticus Geiger</b>*, Zhengxuan Wu*, Christopher Potts, Thomas Icard, Noah D. Goodman <br/>
          <i>CLeaR 2024</i><br/>
          <a href="https://arxiv.org/abs/2303.02536">pdf</a>
          <a href="assets/CLEAR2024.tex">bibtex</a>
        </p>
      </div>

      <div style="height: 100px">
        <p style="margin: 0px 0px 0px 0px">
          <b><i>CEBaB: Estimating the causal effects of real-world concepts on NLP model behavior</i></b><br/>
          Eldar D Abraham, Karel D'Oosterlinck, Amir Feder, Yair Gat, <b>Atticus Geiger</b>, Christopher Potts, Roi Reichart, Zhengxuan Wu <br/>
          <i>NeurIPS 2022</i><br/>
          <a href="https://arxiv.org/abs/2205.14140">pdf</a>
          <a href="assets/NeurIPS2022.tex">bibtex</a>
        </p>
      </div>

      <div style="height: 100px">
        <p style="margin: 0px 0px 0px 0px">
          <b><i>Inducing Causal Structure for Interpretable Neural Network</i></b><br/>
          <b>Atticus Geiger</b>*, Zhengxuan Wu*, Hanson Lu*, Josh Rozner, Elisa Kreiss, Thomas Icard, Noah D. Goodman, Christopher Potts <br/>
          <i>ICML 2022</i><br/>
          <a href="https://arxiv.org/abs/2112.00826">pdf</a>
          <a href="assets/ICML2022.tex">bibtex</a>
        </p>
      </div>

      <div style="height: 100px">
        <p style="margin: 0px 0px 0px 0px">
          <b><i>Causal Abstractions of Neural Networks</i></b><br/>
          <b>Atticus Geiger</b>*, Hanson Lu*, Thomas Icard, Christopher Potts <br/>
          <i>NeurIPS 2021</i><br/>
          <a href="https://arxiv.org/abs/2106.02997">pdf</a>
          <a href="assets/neurips2021.tex">bibtex</a>
        </p>
      </div>

      <div style="height: 100px">
        <p style="margin: 0px 0px 0px 0px">
          <b><i>Neural natural language inference models partially embed theories of lexical entailment and negation</i></b><br/>
          <b>Atticus Geiger</b>, Kyle Richardson, Christopher Potts <br/>
          <i>BlackBoxNLP 2020</i><br/>
          <a href="https://arxiv.org/abs/2004.14623">pdf</a>
          <a href="assets/blackbox.tex">bibtex</a>
        </p>
      </div>

      <div style="height: 100px">
        <p style="margin: 0px 0px 0px 0px">
          <b><i>Posing fair generalization tasks for natural language inference</i></b><br/>
          <b>Atticus Geiger</b>, Ignacio Cases, Lauri Karttunen, Chris Potts <br/>
          <i>EMNLP 2019</i><br/>
          <a href="https://arxiv.org/abs/1911.00811">pdf</a>
          <a href="assets/EMNLP2019.tex">bibtex</a>
        </p>
      </div>


      <footer class="footer container">
        <small>&copy; <b>Atticus Geiger</b> 2021
        </small>
      </footer>
    </div>

  </body>
</html>
